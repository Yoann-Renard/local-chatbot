# On Premise Chatbot

Local chatbot with Ollama & fastHTML

## Run the app

### Download Ollama

Download and install Ollama from https://ollama.com

Pull the model with `ollama pull llama3.1`

### Install dependecies and run the app

`pip install -r requirements`

`python main.py`

You can run any model of your choice compatible with Ollama with `python main.py {MODEL}`
